#  Proyecto Integrado V - RecolecciÃ³n de Datos HistÃ³ricos de TSLA (Tesla Inc.)

Este proyecto implementa una soluciÃ³n automatizada para la recolecciÃ³n continua de datos histÃ³ricos del indicador econÃ³mico *TSLA* desde Yahoo Finanzas, utilizando tÃ©cnicas de scraping web. La informaciÃ³n obtenida se almacena en formatos *CSV* y *SQLite*, asegurando la trazabilidad mediante logs estructurados y automatizaciÃ³n con GitHub Actions.

---

##  Estructura del Proyecto

```
Proyecto_integrado_v_2025/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ update_data.yml         # Flujo de trabajo automatizado en GitHub Actions
â”œâ”€â”€ src/
â”‚   â””â”€â”€ proyecto_integrado_V/
â”‚       â”œâ”€â”€ static/
â”‚       â”‚   â””â”€â”€ data/               # Almacenamiento de archivos CSV y SQLite
â”‚       â”œâ”€â”€ collector.py            # Clase para extracciÃ³n y persistencia de datos
â”‚       â”œâ”€â”€ logger.py               # Clase para manejo de logs
â”‚       â””â”€â”€ main.py                 # Script principal ejecutable
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ report_entrega1.pdf         # Informe tÃ©cnico en formato APA
â”œâ”€â”€ requirements.txt                # Archivo de dependencias
â”œâ”€â”€ setup.py                        # ConfiguraciÃ³n del paquete Python
â””â”€â”€ README.md                       # Este documento
```

---

##  TecnologÃ­as Utilizadas

- *Python 3.9.2*
- requests: Descarga de contenido web
- beautifulsoup4: Parseo HTML de la tabla
- pandas: TransformaciÃ³n y manejo de datos
- sqlite3: Persistencia en base de datos
- GitHub Actions: AutomatizaciÃ³n de recolecciÃ³n continua
- logging: Registro de ejecuciÃ³n por timestamp

---

##  EjecuciÃ³n Local

Sigue estos pasos para ejecutar el proyecto en tu mÃ¡quina local:

bash
# 1. Clonar el repositorio
git clone https://github.com/usuario/proyecto_integrado_v_2025.git
cd proyecto_integrado_v_2025

# 2. Crear y activar un entorno virtual
python -m venv venv
.env\Scripts\Activate.ps1  # PowerShell en Windows

# 3. Instalar las dependencias
pip install -r requirements.txt

# 4. Ejecutar el script principal
python src/proyecto_integrado_V/main.py


Al finalizar, se generarÃ¡n automÃ¡ticamente:

-  BTC_EUR_data.csv con los datos histÃ³ricos (en static/data)
-  btc_eur_data.db con la base SQLite
-  Logs individuales en la carpeta logs/

---

##  AutomatizaciÃ³n en GitHub Actions

Cada vez que se hace push en la rama main, el archivo .github/workflows/update_data.yml activa el siguiente flujo:

1. Configura el entorno y dependencias.
2. Ejecuta el script principal (main.py).
3. Genera o actualiza archivos CSV y DB.
4. Agrega los nuevos archivos al repositorio.
5. Realiza commit y push automÃ¡ticos.

---

## ðŸ“„ DocumentaciÃ³n TÃ©cnica

El informe tÃ©cnico del proyecto estÃ¡ disponible en:


docs/report_entrega1.pdf


Contiene resumen, introducciÃ³n, metodologÃ­a y anÃ¡lisis en formato *APA*.

---

##  Autores

*Davinson Stiven Rincon Campos*
*Estefania Jimenez Tabares*  
Estudiantes de IngenierÃ­a en Desarrollo de Software y Datos  
InstituciÃ³n Universitaria Digital de Antioquia  

---

## ðŸ—“ Ãšltima actualizaciÃ³n

MayoÂ deÂ 2025
